I'll analyze the codebase and documentation to create a comprehensive implementation plan for Feature 5.2: Stage 8 - Visual Definition UI.

Let me start by reading the key files to understand the current state and requirements.

[5 tools called]

Let me continue reading the remaining key files to complete my understanding.

[4 tools called]

Now let me read a few more supporting files to complete my understanding:

[3 tools called]

Perfect! Now I have all the context I need. Let me create a comprehensive implementation plan for Feature 5.2: Stage 8 - Visual Definition UI.

---

# **Feature 5.2: Stage 8 - Visual Definition UI - Implementation Plan**

## **Executive Summary**

This plan details the implementation of Stage 8's complete UI/UX system for defining scene starting visual states. Stage 8 is where users assemble, review, modify, and generate visual references for all assets appearing in a scene. The current implementation uses mock data and a simplified three-panel layout. This plan will replace it with a production-ready system that:

1. **Integrates with Feature 5.1's scene asset instance infrastructure** (already implemented)
2. **Provides asset relevance detection** (AI agent determines which assets are needed)
3. **Enables scene-specific visual state editing** with inheritance from prior scenes
4. **Supports bulk scene asset image generation** with Nano Banana
5. **Integrates the Asset Drawer** for adding assets from global/project libraries

---

## **Architecture Overview**

### **Data Flow**
```
Stage 7 (Shot List) → Stage 8 Entry
    ↓
1. Load Scene Asset Instances (GET /api/projects/:projectId/scenes/:sceneId/assets)
    - Returns existing instances if scene was visited before
    - Returns empty array if first visit
    ↓
2. Trigger Asset Relevance Detection (AI Agent - if no instances exist)
    - Analyzes shot list to determine which assets are needed
    - Returns relevant_assets[] and new_assets_required[]
    ↓
3. User Reviews & Edits Asset Descriptions
    - Scene Visual Elements Panel: grouped list of assets
    - Visual State Editor: modify effective_description
    - Asset Drawer: add missing assets or create new ones
    ↓
4. Bulk Image Generation (Multi-select + Generate button)
    - POST /api/projects/:projectId/scenes/:sceneId/assets/:instanceId/generate-image
    - Uses effective_description + locked visual style capsule
    - Polls for job completion
    ↓
5. Lock & Proceed to Stage 9
```

### **Key Constraints (from PRD)**
- **Stage 8 defines ONLY starting visual conditions** (not mid-scene changes)
- **Inheritance logic**: Scene 1 inherits from Master Assets; Scene N inherits from Scene N-1 end states
- **Status tags** (e.g., "muddy", "torn") carry forward between scenes if `carry_forward: true`
- **Modification tracking**: audit trail for description changes (`modification_count`, `last_modified_field`, `modification_reason`)

---

## **Task Breakdown**

### **Task 1: Backend - Scene Asset Relevance Agent (AI)**

**Purpose**: Automatically detect which assets are needed for a scene based on the locked shot list.

**Files to Create/Modify**:
- `backend/src/services/sceneAssetRelevanceService.ts` (new)
- `backend/src/routes/sceneAssets.ts` (add relevance endpoint)

**Implementation Steps**:

#### **1.1 Create SceneAssetRelevanceService**

```typescript
// backend/src/services/sceneAssetRelevanceService.ts
import { supabase } from '../config/supabase.js';
import { AnthropicClient } from '../services/ai/anthropicClient.js'; // Or OpenAI
import type { SceneAssetRelevanceResult } from '../../types/scene.js';

export class SceneAssetRelevanceService {
  private aiClient: AnthropicClient;

  constructor() {
    this.aiClient = new AnthropicClient();
  }

  /**
   * Analyze shot list to determine which project assets are relevant
   * Adheres to AI-agent-registry-context-flow-architecture.md (lines 668-750)
   */
  async detectRelevantAssets(
    sceneId: string,
    branchId: string
  ): Promise<SceneAssetRelevanceResult> {
    // 1. Fetch scene shot list
    const { data: scene } = await supabase
      .from('scenes')
      .select('id, scene_number, script_excerpt')
      .eq('id', sceneId)
      .single();

    const { data: shots } = await supabase
      .from('shots')
      .select('shot_id, characters_foreground, characters_background, setting, action')
      .eq('scene_id', sceneId)
      .order('shot_order');

    // 2. Get prior scene asset instances (for inheritance context)
    let previousSceneAssetInstances = null;
    if (scene.scene_number > 1) {
      const { data: priorScene } = await supabase
        .from('scenes')
        .select('id')
        .eq('branch_id', branchId)
        .eq('scene_number', scene.scene_number - 1)
        .single();

      if (priorScene) {
        const { data: instances } = await supabase
          .from('scene_asset_instances')
          .select(`
            project_asset_id,
            project_asset:project_assets(id, name, asset_type),
            description_override,
            status_tags,
            effective_description
          `)
          .eq('scene_id', priorScene.id)
          .eq('carry_forward', true);

        previousSceneAssetInstances = instances;
      }
    }

    // 3. Get all project assets (master asset pool)
    const { data: projectAssets } = await supabase
      .from('project_assets')
      .select('id, name, asset_type, description, image_key_url')
      .eq('branch_id', branchId)
      .eq('locked', true);

    // 4. Call AI Agent (Scene Asset Relevance Agent from AI-agent-registry-context-flow-architecture.md)
    const prompt = this.buildRelevancePrompt(scene, shots, previousSceneAssetInstances, projectAssets);
    const aiResponse = await this.aiClient.complete(prompt);

    // 5. Parse AI response into typed structure
    return this.parseRelevanceResponse(aiResponse);
  }

  private buildRelevancePrompt(scene, shots, priorInstances, projectAssets): string {
    // System prompt from AI-agent-registry-context-flow-architecture.md (lines 668-750)
    return `
You are an asset continuity manager. Your role is to determine which Master Assets appear in the current scene and define their starting visual state.

CURRENT SCENE CONTEXT:
Scene Number: ${scene.scene_number}
Script Excerpt: ${scene.script_excerpt}

Shot List:
${shots.map(s => `- Shot ${s.shot_id}: Characters: ${s.characters_foreground.join(', ')}; Setting: ${s.setting}; Action: ${s.action}`).join('\n')}

PREVIOUS SCENE END-STATE:
${priorInstances ? JSON.stringify(priorInstances, null, 2) : 'None (Scene 1)'}

AVAILABLE PROJECT ASSETS:
${projectAssets.map(a => `- ${a.name} (${a.asset_type}): ${a.description}`).join('\n')}

RELEVANCE RULES:
1. Extract all characters explicitly mentioned in the shot list
2. Extract all props explicitly mentioned or implied by action
3. Extract all settings/locations mentioned

STATE INHERITANCE RULES:
1. If an asset appeared in the previous scene, inherit its END state
2. If an asset is new to this scene, inherit from Master Asset definition
3. Flag any assets requiring explicit state modification

OUTPUT REQUIREMENTS:
Generate a JSON object with the following structure:
{
  "scene_id": "${scene.id}",
  "relevant_assets": [
    {
      "project_asset_id": "uuid",
      "name": "Asset Name",
      "asset_type": "character | prop | location",
      "inherited_from": "master | previous_scene_instance",
      "starting_description": "string (inherited or modified)",
      "requires_visual_update": boolean,
      "status_tags_inherited": ["array of strings"],
      "relevance_rationale": "why this asset is needed"
    }
  ],
  "new_assets_required": [
    {
      "name": "string",
      "asset_type": "character | prop | location",
      "description": "string (inferred from shot list)",
      "justification": "why this is needed"
    }
  ]
}

Generate the JSON output now.
`;
  }

  private parseRelevanceResponse(aiResponse: string): SceneAssetRelevanceResult {
    // Parse JSON from AI response (with error handling)
    try {
      const jsonMatch = aiResponse.match(/\{[\s\S]*\}/);
      if (!jsonMatch) throw new Error('No JSON found in AI response');
      return JSON.parse(jsonMatch[0]);
    } catch (error) {
      throw new Error(`Failed to parse AI relevance response: ${error.message}`);
    }
  }
}
```

#### **1.2 Add Relevance Endpoint**

```typescript
// backend/src/routes/sceneAssets.ts (add to existing file)
import { SceneAssetRelevanceService } from '../services/sceneAssetRelevanceService.js';

/**
 * POST /api/projects/:projectId/scenes/:sceneId/assets/detect-relevance
 * AI agent detects which assets are needed for this scene
 */
router.post('/:projectId/scenes/:sceneId/assets/detect-relevance', async (req, res) => {
  try {
    const userId = req.user!.id;
    const { projectId, sceneId } = req.params;

    const { data: project, error: projectError } = await supabase
      .from('projects')
      .select('id, active_branch_id')
      .eq('id', projectId)
      .eq('user_id', userId)
      .single();

    if (projectError || !project) {
      return res.status(404).json({ error: 'Project not found' });
    }

    const { data: scene, error: sceneError } = await supabase
      .from('scenes')
      .select('id, branch_id')
      .eq('id', sceneId)
      .eq('branch_id', project.active_branch_id)
      .single();

    if (sceneError || !scene) {
      return res.status(404).json({ error: 'Scene not found' });
    }

    const relevanceService = new SceneAssetRelevanceService();
    const result = await relevanceService.detectRelevantAssets(sceneId, project.active_branch_id);

    res.json(result);
  } catch (error) {
    console.error('[SceneAssets] Relevance detection error:', error);
    res.status(500).json({
      error: 'Asset relevance detection failed',
      message: error instanceof Error ? error.message : 'Unknown error',
    });
  }
});
```

---

### **Task 2: Frontend Service - Scene Asset Instance Management**

**Purpose**: Create a frontend API client for CRUD operations on scene asset instances.

**Files to Create**:
- `src/lib/services/sceneAssetService.ts` (new)

**Implementation**:

```typescript
// src/lib/services/sceneAssetService.ts
import { supabase } from '@/lib/supabase';
import type {
  SceneAssetInstance,
  CreateSceneAssetInstanceRequest,
  UpdateSceneAssetInstanceRequest,
  SceneAssetRelevanceResult,
} from '@/types/scene';

export interface BulkImageGenerationRequest {
  instanceIds: string[];
}

export interface BulkImageGenerationResult {
  jobId: string;
  totalJobs: number;
  statuses: Array<{
    instanceId: string;
    jobId: string;
    status: 'queued' | 'processing' | 'completed' | 'failed';
  }>;
}

class SceneAssetService {
  /**
   * List all asset instances for a scene
   */
  async listSceneAssets(projectId: string, sceneId: string): Promise<SceneAssetInstance[]> {
    const { data: { session } } = await supabase.auth.getSession();
    if (!session?.access_token) {
      throw new Error('User not authenticated');
    }

    const response = await fetch(
      `/api/projects/${projectId}/scenes/${sceneId}/assets`,
      {
        headers: {
          'Authorization': `Bearer ${session.access_token}`,
        },
      }
    );

    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.error || 'Failed to fetch scene assets');
    }

    return response.json();
  }

  /**
   * Create a new scene asset instance
   */
  async createSceneAsset(
    projectId: string,
    request: CreateSceneAssetInstanceRequest
  ): Promise<SceneAssetInstance> {
    const { data: { session } } = await supabase.auth.getSession();
    if (!session?.access_token) {
      throw new Error('User not authenticated');
    }

    const response = await fetch(
      `/api/projects/${projectId}/scenes/${request.sceneId}/assets`,
      {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${session.access_token}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(request),
      }
    );

    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.error || 'Failed to create scene asset');
    }

    return response.json();
  }

  /**
   * Update scene asset instance
   */
  async updateSceneAsset(
    projectId: string,
    sceneId: string,
    instanceId: string,
    updates: UpdateSceneAssetInstanceRequest
  ): Promise<SceneAssetInstance> {
    const { data: { session } } = await supabase.auth.getSession();
    if (!session?.access_token) {
      throw new Error('User not authenticated');
    }

    const response = await fetch(
      `/api/projects/${projectId}/scenes/${sceneId}/assets/${instanceId}`,
      {
        method: 'PUT',
        headers: {
          'Authorization': `Bearer ${session.access_token}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(updates),
      }
    );

    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.error || 'Failed to update scene asset');
    }

    return response.json();
  }

  /**
   * Delete scene asset instance
   */
  async deleteSceneAsset(
    projectId: string,
    sceneId: string,
    instanceId: string
  ): Promise<void> {
    const { data: { session } } = await supabase.auth.getSession();
    if (!session?.access_token) {
      throw new Error('User not authenticated');
    }

    const response = await fetch(
      `/api/projects/${projectId}/scenes/${sceneId}/assets/${instanceId}`,
      {
        method: 'DELETE',
        headers: {
          'Authorization': `Bearer ${session.access_token}`,
        },
      }
    );

    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.error || 'Failed to delete scene asset');
    }
  }

  /**
   * Trigger asset inheritance from prior scene
   */
  async inheritAssets(projectId: string, sceneId: string): Promise<{ count: number }> {
    const { data: { session } } = await supabase.auth.getSession();
    if (!session?.access_token) {
      throw new Error('User not authenticated');
    }

    const response = await fetch(
      `/api/projects/${projectId}/scenes/${sceneId}/assets/inherit`,
      {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${session.access_token}`,
        },
      }
    );

    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.error || 'Failed to inherit assets');
    }

    return response.json();
  }

  /**
   * Detect relevant assets using AI
   */
  async detectRelevantAssets(
    projectId: string,
    sceneId: string
  ): Promise<SceneAssetRelevanceResult> {
    const { data: { session } } = await supabase.auth.getSession();
    if (!session?.access_token) {
      throw new Error('User not authenticated');
    }

    const response = await fetch(
      `/api/projects/${projectId}/scenes/${sceneId}/assets/detect-relevance`,
      {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${session.access_token}`,
        },
      }
    );

    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.error || 'Failed to detect relevant assets');
    }

    return response.json();
  }

  /**
   * Generate image for single scene asset instance
   */
  async generateSceneAssetImage(
    projectId: string,
    sceneId: string,
    instanceId: string
  ): Promise<{ jobId: string; status: string }> {
    const { data: { session } } = await supabase.auth.getSession();
    if (!session?.access_token) {
      throw new Error('User not authenticated');
    }

    const response = await fetch(
      `/api/projects/${projectId}/scenes/${sceneId}/assets/${instanceId}/generate-image`,
      {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${session.access_token}`,
        },
      }
    );

    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.error || 'Failed to generate image');
    }

    return response.json();
  }

  /**
   * Bulk generate images for multiple scene asset instances
   */
  async bulkGenerateImages(
    projectId: string,
    sceneId: string,
    instanceIds: string[]
  ): Promise<BulkImageGenerationResult> {
    const results = await Promise.allSettled(
      instanceIds.map(id => this.generateSceneAssetImage(projectId, sceneId, id))
    );

    const statuses = results.map((result, idx) => {
      if (result.status === 'fulfilled') {
        return {
          instanceId: instanceIds[idx],
          jobId: result.value.jobId,
          status: result.value.status as any,
        };
      } else {
        return {
          instanceId: instanceIds[idx],
          jobId: '',
          status: 'failed' as const,
        };
      }
    });

    return {
      jobId: `bulk-${Date.now()}`,
      totalJobs: instanceIds.length,
      statuses,
    };
  }
}

export const sceneAssetService = new SceneAssetService();
```

---

### **Task 3: UI Component - Rebuild Stage8VisualDefinition**

**Purpose**: Replace mock data with production logic; implement three-panel layout with real API integration.

**Files to Modify**:
- `src/components/pipeline/Stage8VisualDefinition.tsx`

**Key Changes**:

1. **Data Loading on Mount**:
   - Fetch scene asset instances from API
   - If empty, optionally trigger asset relevance detection (or show empty state with "Detect Assets" button)

2. **Scene Visual Elements Panel (Left)**:
   - Group assets by type (Characters, Locations, Props)
   - Display source badge (Master, Prior Scene, New)
   - Show status: Unreviewed, Edited, Locked (based on `image_key_url` and `modification_count`)
   - Multi-select checkboxes for bulk generation

3. **Visual State Editor (Center)**:
   - Editable `effective_description` textarea
   - Display `project_asset` details (name, type, master image)
   - Show inheritance info (`inherited_from_instance_id`)
   - Display audit trail (`modification_count`, `last_modified_field`)
   - Lock/Unlock button (updates `modification_reason`)

4. **Asset Drawer (Right)**:
   - **Add from Project Assets** button → opens `AssetDrawer` component
   - **Create New Scene Asset** button → inline form
   - Drag-and-drop support (optional enhancement)

**Pseudocode Structure**:

```typescript
export function Stage8VisualDefinition({ sceneId, onComplete, onBack, projectId }: Props) {
  const [sceneAssets, setSceneAssets] = useState<SceneAssetInstance[]>([]);
  const [selectedAsset, setSelectedAsset] = useState<SceneAssetInstance | null>(null);
  const [selectedForGeneration, setSelectedForGeneration] = useState<string[]>([]);
  const [loading, setLoading] = useState(true);
  const [assetDrawerOpen, setAssetDrawerOpen] = useState(false);

  // On mount: fetch scene assets
  useEffect(() => {
    loadSceneAssets();
  }, [sceneId, projectId]);

  async function loadSceneAssets() {
    setLoading(true);
    try {
      const assets = await sceneAssetService.listSceneAssets(projectId, sceneId);
      setSceneAssets(assets);
      
      // If no assets exist, optionally auto-detect or show prompt
      if (assets.length === 0) {
        // Option A: Auto-detect
        await handleDetectRelevantAssets();
        
        // Option B: Show empty state with manual "Detect Assets" button
        // (Choose based on UX preference)
      }
    } catch (error) {
      toast.error(`Failed to load scene assets: ${error.message}`);
    } finally {
      setLoading(false);
    }
  }

  async function handleDetectRelevantAssets() {
    // Call AI agent to detect relevant assets
    // Then create scene asset instances for each relevant_asset
    // Refresh list
  }

  async function handleBulkGenerate() {
    setGenerating(true);
    try {
      const result = await sceneAssetService.bulkGenerateImages(
        projectId,
        sceneId,
        selectedForGeneration
      );
      
      // Poll for job completion (or use WebSocket/SSE)
      await pollJobCompletion(result.statuses);
      
      toast.success('Images generated successfully');
      await loadSceneAssets(); // Refresh to show new images
      setSelectedForGeneration([]);
    } catch (error) {
      toast.error(`Bulk generation failed: ${error.message}`);
    } finally {
      setGenerating(false);
    }
  }

  // Render three-panel layout (similar to current mock structure)
  return (
    <div className="flex-1 flex overflow-hidden">
      {/* Left: Scene Visual Elements Panel */}
      <SceneAssetListPanel
        assets={sceneAssets}
        selectedAsset={selectedAsset}
        selectedForGeneration={selectedForGeneration}
        onSelectAsset={setSelectedAsset}
        onToggleSelection={handleToggleSelection}
        onBulkGenerate={handleBulkGenerate}
      />

      {/* Center: Visual State Editor */}
      <VisualStateEditorPanel
        selectedAsset={selectedAsset}
        onUpdateAsset={handleUpdateAsset}
        onLockAsset={handleLockAsset}
        projectId={projectId}
        sceneId={sceneId}
      />

      {/* Right: Asset Drawer Trigger + Actions */}
      <AssetDrawerTriggerPanel
        onOpenAssetDrawer={() => setAssetDrawerOpen(true)}
        onCreateNewAsset={handleCreateNewAsset}
        onBack={onBack}
        onComplete={onComplete}
      />

      {/* Asset Drawer Modal */}
      <AssetDrawer
        projectId={projectId}
        isOpen={assetDrawerOpen}
        onClose={() => setAssetDrawerOpen(false)}
        onAssetCloned={handleAssetClonedToProject}
      />
    </div>
  );
}
```

---

### **Task 4: UI Subcomponent - SceneAssetListPanel (Left Panel)**

**Purpose**: Render grouped list of scene asset instances with multi-select and status indicators.

**Files to Create**:
- `src/components/pipeline/Stage8/SceneAssetListPanel.tsx` (new)

**Features**:
- Group by asset type (Characters, Locations, Props)
- Type icons (User, MapPin, Package from lucide-react)
- Status badges: Unreviewed (gray), Edited (amber), Locked (emerald)
- Checkbox for bulk generation selection
- Click to select asset for editing
- Bulk generation button at bottom (disabled if no selection)

**Example Structure**:
```tsx
export function SceneAssetListPanel({
  assets,
  selectedAsset,
  selectedForGeneration,
  onSelectAsset,
  onToggleSelection,
  onBulkGenerate,
  isGenerating,
}: Props) {
  const groupedAssets = useMemo(() => ({
    character: assets.filter(a => a.project_asset?.asset_type === 'character'),
    location: assets.filter(a => a.project_asset?.asset_type === 'location'),
    prop: assets.filter(a => a.project_asset?.asset_type === 'prop'),
  }), [assets]);

  const getReviewStatus = (asset: SceneAssetInstance): 'unreviewed' | 'edited' | 'locked' => {
    if (!asset.image_key_url) return 'unreviewed';
    if (asset.modification_count && asset.modification_count > 0) return 'edited';
    return 'locked';
  };

  return (
    <motion.div className="w-80 border-r border-border/50 bg-card/30 backdrop-blur-sm flex flex-col">
      <div className="p-4 border-b border-border/50">
        <h2 className="font-display text-lg font-semibold">Scene Assets</h2>
        <p className="text-xs text-muted-foreground mt-1">
          {assets.length} assets • {assets.filter(a => a.image_key_url).length} with visuals
        </p>
      </div>

      <ScrollArea className="flex-1">
        <div className="p-2">
          {Object.entries(groupedAssets).map(([type, typeAssets]) => (
            <AssetTypeGroup
              key={type}
              type={type}
              assets={typeAssets}
              selectedAssetId={selectedAsset?.id}
              selectedForGeneration={selectedForGeneration}
              onSelectAsset={onSelectAsset}
              onToggleSelection={onToggleSelection}
              getReviewStatus={getReviewStatus}
            />
          ))}
        </div>
      </ScrollArea>

      <div className="p-4 border-t border-border/50">
        <Button
          variant="gold"
          className="w-full"
          disabled={selectedForGeneration.length === 0 || isGenerating}
          onClick={onBulkGenerate}
        >
          {isGenerating ? (
            <>
              <RefreshCw className="w-4 h-4 mr-2 animate-spin" />
              Generating ({selectedForGeneration.length})...
            </>
          ) : (
            <>
              <Sparkles className="w-4 h-4 mr-2" />
              Generate Visuals ({selectedForGeneration.length})
            </>
          )}
        </Button>
      </div>
    </motion.div>
  );
}
```

---

### **Task 5: UI Subcomponent - VisualStateEditorPanel (Center Panel)**

**Purpose**: Display and edit the selected scene asset instance's visual description.

**Files to Create**:
- `src/components/pipeline/Stage8/VisualStateEditorPanel.tsx` (new)

**Features**:
- Displays `project_asset` master details (name, type, base description, master image)
- Editable `effective_description` textarea (updates `description_override`)
- Shows inheritance chain (`inherited_from_instance_id`)
- Displays audit trail (`modification_count`, `last_modified_field`, `modification_reason`)
- "Generate Image" button (single asset)
- "Lock Asset" button (once image is generated and approved)
- Status tags editor (chips for "muddy", "bloody", etc.)
- Carry forward toggle

**Example Structure**:
```tsx
export function VisualStateEditorPanel({
  selectedAsset,
  onUpdateAsset,
  onGenerateImage,
  projectId,
  sceneId,
}: Props) {
  const [editedDescription, setEditedDescription] = useState('');
  const [statusTags, setStatusTags] = useState<string[]>([]);
  const [carryForward, setCarryForward] = useState(true);

  useEffect(() => {
    if (selectedAsset) {
      setEditedDescription(selectedAsset.effective_description);
      setStatusTags(selectedAsset.status_tags);
      setCarryForward(selectedAsset.carry_forward);
    }
  }, [selectedAsset]);

  const handleSaveDescription = async () => {
    if (!selectedAsset) return;
    
    await onUpdateAsset(selectedAsset.id, {
      descriptionOverride: editedDescription,
      statusTags,
      carryForward,
      modificationReason: 'User edited description in Stage 8',
    });
  };

  if (!selectedAsset) {
    return (
      <div className="flex-1 flex items-center justify-center">
        <p className="text-muted-foreground">Select an asset to edit</p>
      </div>
    );
  }

  return (
    <motion.div className="flex-1 flex flex-col overflow-hidden">
      <div className="p-4 border-b border-border/50">
        <div className="flex items-center gap-3">
          <AssetTypeIcon type={selectedAsset.project_asset?.asset_type} />
          <div>
            <h3 className="text-lg font-semibold">{selectedAsset.project_asset?.name}</h3>
            <p className="text-xs text-muted-foreground">
              {selectedAsset.inherited_from_instance_id ? 'Inherited from prior scene' : 'From Master Assets'}
            </p>
          </div>
        </div>
      </div>

      <ScrollArea className="flex-1">
        <div className="p-6 space-y-6">
          {/* Master Asset Reference */}
          <MasterAssetReference asset={selectedAsset.project_asset} />

          {/* Scene-Specific Description Editor */}
          <DescriptionEditor
            value={editedDescription}
            onChange={setEditedDescription}
            onSave={handleSaveDescription}
          />

          {/* Status Tags Editor */}
          <StatusTagsEditor
            tags={statusTags}
            onChange={setStatusTags}
          />

          {/* Carry Forward Toggle */}
          <CarryForwardToggle
            value={carryForward}
            onChange={setCarryForward}
          />

          {/* Image Display/Generation */}
          <ImageSection
            imageUrl={selectedAsset.image_key_url}
            onGenerate={() => onGenerateImage(selectedAsset.id)}
          />

          {/* Audit Trail */}
          {selectedAsset.modification_count && selectedAsset.modification_count > 0 && (
            <AuditTrail
              modificationCount={selectedAsset.modification_count}
              lastModifiedField={selectedAsset.last_modified_field}
              modificationReason={selectedAsset.modification_reason}
            />
          )}
        </div>
      </ScrollArea>
    </motion.div>
  );
}
```

---

### **Task 6: Asset Drawer Integration**

**Purpose**: Allow users to add assets from global/project libraries to the current scene.

**Files to Modify**:
- `src/components/pipeline/AssetDrawer.tsx` (minor modifications for scene context)
- `src/components/pipeline/Stage8VisualDefinition.tsx` (integration)

**Implementation**:

#### **6.1 Modify AssetDrawer for Scene Assignment**

**Current behavior**: AssetDrawer clones global assets into `project_assets`.

**New behavior**: After cloning into `project_assets`, optionally create a `scene_asset_instance` for the current scene.

**Approach**: Add optional `sceneId` prop to AssetDrawer. When provided, after cloning, automatically create a scene instance.

```typescript
// Modified AssetDrawer.tsx
interface AssetDrawerProps {
  projectId: string;
  isOpen: boolean;
  onClose: () => void;
  onAssetCloned?: (asset: ProjectAsset) => void;
  filterType?: AssetType;
  // NEW: Optional scene context for auto-creating scene instances
  sceneId?: string;
  onSceneInstanceCreated?: (instance: SceneAssetInstance) => void;
}

// In handleCloneAsset (after cloning to project_assets):
if (sceneId && onSceneInstanceCreated) {
  // Create scene asset instance
  const instance = await sceneAssetService.createSceneAsset(projectId, {
    sceneId,
    projectAssetId: clonedAsset.id,
    descriptionOverride: null, // Use master description initially
    statusTags: [],
    carryForward: true,
  });
  
  onSceneInstanceCreated(instance);
}
```

#### **6.2 Stage 8 Integration**

```tsx
// In Stage8VisualDefinition.tsx
<AssetDrawer
  projectId={projectId}
  sceneId={sceneId}
  isOpen={assetDrawerOpen}
  onClose={() => setAssetDrawerOpen(false)}
  onSceneInstanceCreated={handleSceneInstanceCreated}
/>

async function handleSceneInstanceCreated(instance: SceneAssetInstance) {
  // Refresh scene assets list
  await loadSceneAssets();
  toast.success(`Added ${instance.project_asset?.name} to scene`);
  setAssetDrawerOpen(false);
}
```

---

### **Task 7: Bulk Image Generation Orchestration**

**Purpose**: Handle multi-select image generation with job polling and progress feedback.

**Implementation Strategy**:
1. User selects multiple assets via checkboxes
2. Clicks "Generate Visuals (N)" button
3. Frontend calls `sceneAssetService.bulkGenerateImages(projectId, sceneId, instanceIds[])`
4. Service initiates parallel generation jobs
5. Poll each job individually (or use a unified polling mechanism)
6. Update UI with per-asset status (queued → generating → completed/failed)
7. On completion, refresh scene assets list to show new `image_key_url` values

**UI Feedback**:
- Show spinner on "Generate Visuals" button
- Display toast notifications for completion/failure
- Optionally show individual job statuses in a modal (advanced)

**Example Polling Logic**:
```typescript
async function pollJobCompletion(statuses: Array<{ instanceId: string; jobId: string }>) {
  const pollInterval = 2000; // 2 seconds
  const maxAttempts = 60; // 2 minutes total

  for (let attempt = 0; attempt < maxAttempts; attempt++) {
    const allCompleted = await Promise.all(
      statuses.map(async ({ jobId }) => {
        const job = await fetch(`/api/images/jobs/${jobId}`).then(r => r.json());
        return job.status === 'completed' || job.status === 'failed';
      })
    );

    if (allCompleted.every(c => c)) {
      break; // All jobs finished
    }

    await new Promise(resolve => setTimeout(resolve, pollInterval));
  }
}
```

---

### **Task 8: Empty State & Asset Detection Flow**

**Purpose**: Handle first-time Stage 8 entry for a scene with no prior asset instances.

**UX Flow**:
1. User enters Stage 8 for the first time
2. No scene asset instances exist yet
3. Show empty state with two options:
   - **"Detect Required Assets"** (AI agent) → auto-detects from shot list
   - **"Add Assets Manually"** → opens Asset Drawer

**Implementation**:

```tsx
// In Stage8VisualDefinition.tsx
if (loading) {
  return <LoadingSpinner />;
}

if (sceneAssets.length === 0) {
  return (
    <EmptyStatePanel
      onDetectAssets={handleDetectAndPopulateAssets}
      onAddManually={() => setAssetDrawerOpen(true)}
    />
  );
}

async function handleDetectAndPopulateAssets() {
  try {
    setDetecting(true);
    
    // 1. Call AI agent to detect relevant assets
    const relevance = await sceneAssetService.detectRelevantAssets(projectId, sceneId);
    
    // 2. Create scene asset instances for each relevant_asset
    const createPromises = relevance.relevant_assets.map(ra => 
      sceneAssetService.createSceneAsset(projectId, {
        sceneId,
        projectAssetId: ra.project_asset_id,
        descriptionOverride: ra.starting_description !== ra.project_asset?.description
          ? ra.starting_description
          : null,
        statusTags: ra.status_tags_inherited,
        carryForward: true,
      })
    );
    
    await Promise.all(createPromises);
    
    // 3. Refresh list
    await loadSceneAssets();
    
    toast.success(`Detected ${relevance.relevant_assets.length} relevant assets`);
    
    // 4. Handle new_assets_required (show modal for user to review/create)
    if (relevance.new_assets_required.length > 0) {
      setNewAssetsRequired(relevance.new_assets_required);
      setNewAssetsModalOpen(true);
    }
  } catch (error) {
    toast.error(`Asset detection failed: ${error.message}`);
  } finally {
    setDetecting(false);
  }
}
```

**EmptyStatePanel Component**:
```tsx
function EmptyStatePanel({ onDetectAssets, onAddManually }: Props) {
  return (
    <div className="flex-1 flex items-center justify-center">
      <Card className="max-w-md text-center p-8">
        <Sparkles className="w-16 h-16 mx-auto mb-4 text-primary" />
        <h2 className="text-2xl font-bold mb-2">No Assets Defined Yet</h2>
        <p className="text-muted-foreground mb-6">
          Define which characters, props, and locations appear at the start of this scene.
        </p>
        
        <div className="space-y-3">
          <Button variant="gold" className="w-full" onClick={onDetectAssets}>
            <Brain className="w-4 h-4 mr-2" />
            Detect Required Assets (AI)
          </Button>
          
          <Button variant="outline" className="w-full" onClick={onAddManually}>
            <Plus className="w-4 h-4 mr-2" />
            Add Assets Manually
          </Button>
        </div>
      </Card>
    </div>
  );
}
```

---

### **Task 9: Status Tags Editor**

**Purpose**: Allow users to add/remove status metadata tags (e.g., "muddy", "bloody", "torn") to scene asset instances.

**Implementation**:

```tsx
// src/components/pipeline/Stage8/StatusTagsEditor.tsx
export function StatusTagsEditor({ tags, onChange }: Props) {
  const [inputValue, setInputValue] = useState('');

  const handleAddTag = () => {
    if (inputValue.trim() && !tags.includes(inputValue.trim())) {
      onChange([...tags, inputValue.trim()]);
      setInputValue('');
    }
  };

  const handleRemoveTag = (tag: string) => {
    onChange(tags.filter(t => t !== tag));
  };

  return (
    <div>
      <label className="text-sm font-medium flex items-center gap-2 mb-2">
        <Tag className="w-4 h-4 text-primary" />
        Status Tags (Conditions)
      </label>
      
      <div className="flex flex-wrap gap-2 mb-2">
        {tags.map(tag => (
          <Badge key={tag} variant="secondary" className="gap-1">
            {tag}
            <X
              className="w-3 h-3 cursor-pointer hover:text-destructive"
              onClick={() => handleRemoveTag(tag)}
            />
          </Badge>
        ))}
      </div>

      <div className="flex gap-2">
        <Input
          value={inputValue}
          onChange={(e) => setInputValue(e.target.value)}
          onKeyDown={(e) => e.key === 'Enter' && handleAddTag()}
          placeholder="Add tag (e.g., muddy, torn)"
        />
        <Button size="sm" onClick={handleAddTag}>
          <Plus className="w-4 h-4" />
        </Button>
      </div>

      <p className="text-xs text-muted-foreground mt-2">
        Tags describe visual conditions (muddy, bloody, torn). They carry forward to next scene if enabled.
      </p>
    </div>
  );
}
```

---

### **Task 10: Gatekeeper Logic - Proceed to Stage 9**

**Purpose**: Ensure all required assets have generated images before allowing progression to Stage 9.

**Validation**:
- Check that all scene asset instances have `image_key_url` populated
- (Optional) Check that at least one asset exists per type mentioned in shot list

**Implementation**:

```tsx
// In Stage8VisualDefinition.tsx
async function handleProceedToStage9() {
  // Validate that all assets have images
  const missingImages = sceneAssets.filter(a => !a.image_key_url);

  if (missingImages.length > 0) {
    toast.error(
      `Cannot proceed: ${missingImages.length} asset(s) missing visual references. Generate images first.`
    );
    return;
  }

  // All checks passed
  onComplete();
}
```

---

### **Task 11: Testing & Polish**

**Testing Checklist**:
1. **Asset Inheritance**: Verify Scene 1 bootstraps from `project_assets`; Scene N inherits from Scene N-1
2. **AI Relevance Detection**: Test with various shot lists; ensure correct asset identification
3. **Bulk Image Generation**: Test with 1, 5, and 10+ assets; verify polling and error handling
4. **Status Tags**: Add/remove tags; verify carry_forward behavior
5. **Audit Trail**: Make multiple edits; verify `modification_count` increments
6. **Asset Drawer Integration**: Clone global asset → verify scene instance creation
7. **Empty State**: Test first-time entry → detect assets → populate list
8. **Gatekeeper**: Attempt to proceed without images → verify validation

**Polish Items**:
- Add loading skeletons for asset list
- Add error boundaries for API failures
- Add keyboard shortcuts (e.g., Ctrl+S to save description)
- Add drag-and-drop reordering (optional enhancement)
- Add asset search/filter in left panel (if asset count is high)

---

## **Summary of Implementation Order**

1. **Backend - AI Relevance Agent** (Task 1)
2. **Backend - Relevance Endpoint** (Task 1.2)
3. **Frontend Service Layer** (Task 2)
4. **UI - Rebuild Stage8VisualDefinition** (Task 3)
5. **UI - SceneAssetListPanel** (Task 4)
6. **UI - VisualStateEditorPanel** (Task 5)
7. **Asset Drawer Integration** (Task 6)
8. **Bulk Image Generation** (Task 7)
9. **Empty State & Detection Flow** (Task 8)
10. **Status Tags Editor** (Task 9)
11. **Gatekeeper Logic** (Task 10)
12. **Testing & Polish** (Task 11)

---

## **Dependencies & Prerequisites**

- ✅ **Feature 5.1 (Scene Asset Instances)** - Already implemented
- ✅ **Stage 7 (Shot List)** - Must be locked before entering Stage 8
- ✅ **Stage 5 (Visual Style Lock)** - Required for image generation
- ❌ **AI Client Service** - May need to create `AnthropicClient` or `OpenAIClient` for relevance agent (if not already present)

---

## **Estimated Effort**

- **Backend (Tasks 1-2)**: ~6-8 hours
- **Frontend Service (Task 2)**: ~2-3 hours
- **UI Components (Tasks 3-5)**: ~10-12 hours
- **Asset Drawer Integration (Task 6)**: ~3-4 hours
- **Bulk Generation & Polling (Task 7)**: ~4-5 hours
- **Empty State & Detection (Task 8)**: ~3-4 hours
- **Status Tags & Polish (Tasks 9-11)**: ~4-6 hours

**Total**: ~32-42 hours