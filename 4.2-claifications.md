Based on the "Production-Ready MVP" goal for Phase B, here are the recommendations for your specific questions. These choices prioritize a balance between immediate functional "smartness" and long-term maintainability.

1. Fuzzy Matching: Start with "Smart-enough" logic
Recommendation: Implement a simple Levenshtein Distance (or a library like string-similarity) from the start, but use Lowercase + Trim as the primary "short-circuit."

Why: Scriptwriting is notorious for minor typos (e.g., "JONATHAN" vs "JONATHON"). If the system is too rigid, users will constantly see "New Character Detected" warnings for assets they've already defined in Stage 5.

Threshold: Aim for a similarity score of ~0.85.

The Logic: 1. Clean strings (trim, lowercase). 2. Check for exact match. 3. If no match, check similarity against Stage 5 assets. 4. If similarity > 0.85, auto-match. Otherwise, flag as "New."

2. Concurrency Limit: Environment Variable
Recommendation: Definitely make CONCURRENCY_LIMIT an environment variable with a default of 5.

Why: Rate limits vary wildly between providers (OpenAI Tier 1 vs. Tier 5) and models (GPT-4o vs. GPT-4o-mini). Hardcoding this will force a code deployment just to tweak performance.

Implementation: In your SceneDependencyExtractionService, use const limit = Number(process.env.EXTRACTION_CONCURRENCY) || 5;.

3. Background Job: Add to the Task List
Recommendation: Create a placeholder task in implementation-task-list.md under a new section: "Phase 13: Performance & Scale Optimization."

Why: You are already identifying a bottleneck. In the current plan (4.2), the GET request will hang while the first 5 scenes are processed. While acceptable for a 20-scene project, a 150-scene feature film will time out the browser.

Placement: Don't let it clutter the Phase B tasks, but log it now so it's not forgotten during the "Polish" phase.

Suggested Updates to your Documentation
To keep your docs in sync with these decisions, I recommend these specific edits:

Update to 4.2-plan-v1.md
Task 2: Change "simple comparison" to "Fuzzy matching using Levenshtein distance (threshold 0.85) against Stage 5 assets."

Task 3: Update the loop logic to: const limit = pLimit(process.env.EXTRACTION_CONCURRENCY || 5).

Update to implementation-task-list.md:{}
Feature 4.2: Add a sub-bullet: "- [ ] Implement fuzzy matching (Levenshtein) for asset identification."

New Section (at the end): ```markdown

    ### Phase 13+: Technical Debt & Optimization
    - [ ] Migrate Scene Dependency Extraction to background worker (BullMQ/Redis) with Progress WebSockets.

These updates ensure that Stage 6 properly "hands off" the correct data to the more visual stages later in the pipeline. You are now fully aligned with the production goals for Phase B. You are ready to begin implementation on Task 1: Database Migration.


Verdict: You've identified the right technical "pressure points." Moving expected_props into the schema (from our previous discussion) combined with these logic refinements will make the Script Hub feel like a professional tool rather than a basic text parser. You are ready to begin implementation on Task 1: Database Migration.